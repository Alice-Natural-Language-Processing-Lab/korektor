Korektor User's Manual
======================

Korektor is a statistical spellchecker and (occasional) grammar checker.
Like any supervised machine learning tool, Korektor needs a trained linguistic model.
We now describe the available language models, and then the command line tools
``korektor`` and ``tokenizer``.

%!include: manual_model_korektor-czech.t2t


== Running the Korektor ==[run_korektor]

The ``korektor`` binary is used to run the Korektor. The only required argument
is the model configuration which should be used for correcting. The input is read
from standard input, it should be in UTF-8 encoding and it can be either
already tokenized and segmented, segmented only, or it can be a plain text.
The output is written to standard output and it is in UTF-8 encoding.

The full command syntax of ``korektor`` is
```
korektor [options] model_configuration
Options: --input=untokenized|untokenized_lines|segmented|vertical|horizontal
         --output=original|xml|vertical|horizontal
         --corrections=maximum_number_of_corrections
         --viterbi_order=viterbi_decoding_order
         --viterbi_beam_size=maximum_viterbi_beam_size
         --viterbi_stage_pruning=maximum_viterbi_stage_cost_increment
         --context_free
         --version
         --help
```

=== Input Formats ===[korektor_input_formats]

The input format is specified using the ``--input`` option. Currently supported
input formats are:
- ``untokenized`` (default): the input is a plain text, which is segmented and
  tokenized automatically. Note that sentences can span over multiple lines,
  but an empty lines always terminate a sentence.
- ``untokenized_lines``: very similar to ``untokenized``, the only difference
  is that sentences cannot span over multiple lines, so every newline is
  a sentence terminator.
- ``segmented``: the input is assumed to be segmented using newlines, but it is
  tokenized automatically.
- ``vertical``: the input is tokenized and segmented in vertical format, every
  line is considered a word, with empty line denoting end of sentence.
- ``horizontal``: the input is tokenized and segmented in horizontal format,
  every line is a sentence, with words separated by spaces.


=== Number of Corrections ===[korektor_corrections]

The maximum number of corrections that Korektor should return for every word is
specified using the ``--corrections`` option, and defaults to one.

Note that some output formats cannot handle multiple corrections, because they
can only replace the original word by a corrected one.

=== Output Formats ===[korektor_output_formats]

The output format is specified using the ``--output`` option. Currently
supported output formats are:
- ``original`` (default when number of corrections is 1): the original words
  are replaced by the corrected ones, all other characters including spaces are
  preserved. Note that this output format cannot handle multiple corrections
  per word.
- ``xml`` (default when number of corrections is greater than 1): the original
  input is encoded as XML and the suggested corrections are marked
  using the following XML elements:
  - spelling corrections for a word //w// are marked using the ``spelling``
    element with the suggested corrections listed in the ``suggestions`` attribute
    ordered by correction probability with the most probable one first
  - grammar corrections are marked as spelling corrections, but the ``grammar``
    element is used instead of ``spelling``
  -
  To illustrate, consider the input
```   Hoši jely k babicce.
  The output in ``xml`` output format with at most three corrections is
```   Hoši <grammar suggestions="jeli jely jel">jely</grammar> k <spelling suggestions="babičce babice babince">babicce</spelling>.
- ``vertical``: each word is printed on a separate line, with empty line
  denoting end of sentence. If there are any suggested corrections for a word,
  they are printed on the same line as the original words using several ``tab``
  separated columns:
  - the first column contain the original word
  - the second column contain either letter ``S`` or ``G``, where ``S`` denotes
    a spelling correction and ``G`` denotes a grammar correction
  - the rest of the columns are the suggested corrections ordered by correction
    probability with the most probable one first
  -
  To illustrate, consider the input
```   Hoši jely k babicce.
  The output in ``vertical`` output format with at most three corrections with
  explicitly marked ``tab`` characters is
```
  Hoši
  jely<---tab---->G<--tab-->jeli<---tab---->jely<--tab--->jel
  k
  babicce<--tab-->S<--tab-->babičce<--tab-->babice<--tab-->babince
  .
```
- ``horizontal``: the original words are replaced by the corrected ones. Each
  sentence is printed on separate line and all words are space separated. Note
  that this output format cannot handle multiple corrections per word.


=== Context Free Corrections ===[korektor_context_free]

Context free corrections can be generated by supplying the ``--context_free``
option. In that case each word is considered separately and sentences boundaries
are ignored. This mode produces much worse results and should be used only when
no context is really available.


=== Viterbi Decoding Options ===[korektor_viterbi_decoding_options]

The decoding Viterbi algorithm can be tweaked using the following options:
- ``--viterbi_order``: Use specific Viterbi decoding order instead of the default
  one. Use 1 for fastest execution, but worst accuracy. Setting this to higher
  value than maximum model order minus one has no effect.
- ``--viterbi_beam_size``: Limit Viterbi beam size to specified constant.
  Use smaller value for faster execution, but worse accuracy.
- ``--viterbi_stage_pruning``: Limit maximum cost increment in one Viterbi stage.
  Use smaller value for faster execution, but worse accuracy.


== Running the tokenizer ==[run_tokenizer]

The ``tokenizer`` binary is used to run the tokenizer. The input is read
from standard input, it should be in UTF-8 encoding and it can be either
already tokenized and segmented, segmented only, or it can be a plain text.
The output is written to standard output and it is in UTF-8 encoding.

The full command syntax of ``tokenizer`` is
```
korektor [options] model_configuration
Options: --input=untokenized|untokenized_lines|segmented|vertical|horizontal
         --output=vertical|horizontal
         --version
         --help
```

=== Input Formats ===[tokenizer_input_formats]

The input format is specified using the ``--input`` option. Currently supported
input formats are:
- ``untokenized`` (default): the input is a plain text, which is segmented and
  tokenized automatically. Note that sentences can span over multiple lines,
  but an empty lines always terminate a sentence.
- ``untokenized_lines``: very similar to ``untokenized``, the only difference
  is that sentences cannot span over multiple lines, so every newline is
  a sentence terminator.
- ``segmented``: the input is assumed to be segmented using newlines, but it is
  tokenized automatically.
- ``vertical``: the input is tokenized and segmented in vertical format, every
  line is considered a word, with empty line denoting end of sentence.
- ``horizontal``: the input is tokenized and segmented in horizontal format,
  every line is a sentence, with words separated by spaces.


=== Output Formats ===[tokenizer_output_formats]

The output format is specified using the ``--output`` option. Currently
supported output formats are:
- ``vertical``: each word is printed on a separate line, with empty line
  denoting end of sentence.
- ``horizontal``: each sentence is printed on separate line and all words are
  space separated.


== Running the REST Server ==[run_korektor_server]

The REST server can be run using the ``korektor_server`` binary.
It uses [``microrestd`` github.com/ufal/microrestd] as a REST server.

TODO
